# Copyright (c) 2021, Keane Lucas, Mahmood Sharif, Michael K. Reiter, Lujo Bauer, and Saurabh Shintre
# This file is code used in Malware Makeover

"""
Randomize multiple binaries
"""
from __future__  import division
import random
import time
from functools import partial
from multiprocessing import Pool, Process, Value, Lock
import multiprocessing
random.seed(time.time())
import glob
import os
import sys
import logging
sys.setrecursionlimit(10000000)
sys.path.append('/OpenMalAttack/ThirdParty/MakeOver/enhanced-binary-randomization/')
sys.path.append('/OpenMalAttack/ThirdParty/MakeOver/enhanced-binary-randomization/orp')
import peLib
import copy
import requests
import func
import inp
import swap
import reorder
import equiv
import preserv
import disp
import semnops
from randtoolkit import reanalyze_functions, patch

from pathlib import Path
from utils.utils4makeover import create_logger, MalconvClient, parse_log, judge_grad
from attackers.base import Problem_Space
from classifiers.base import Classifier
from utils.file_handler import calc_sha256


def attack_for_one_data(data, clsf, n_randomize, size_increasement):
  try:
    return _attack_for_one_data(data, clsf, n_randomize, size_increasement)
  except:
    return calc_sha256(data), False


def _attack_for_one_data(data, clsf, n_randomize, size_increasement):
  start_time = time.time()
  saved_root = os.path.join('/home/zhoubolin_tmp/MakeOver/1013/enhanced-binary-diversification/saved_samples', clsf.name, clsf.threshold_type)
  input_file = data
  data_hash = calc_sha256(data)
  origin_size = len(input_file) # os.path.getsize(input_file)
  size_increasement_budget = int(origin_size*size_increasement)
  ALLOWED_TRANSFORMS = ['equiv', 'swap', 'preserv', 'reorder', 'disp', 'semnops']
  orig_bytez = input_file # open(input_file,'rb').read()
  
  orig_embed_x, orig_embed_x_grad, orig_score = clsf.get_score(orig_bytez)

  if orig_score<clsf.clsf_threshold:
    return data_hash, data, True
  
  pe_file, epilog = peLib.read_pe(pe_path=input_file, remove_rubbish=False)

  min_embed_x, min_embed_x_grad, min_score = orig_embed_x, orig_embed_x_grad, orig_score
  min_score_bytez = copy.deepcopy(pe_file.__data__[:])

  # init DispState
  disp_state = disp.DispState(pe_file)
  imagebase = disp_state.peinfo.getImageBase()
  
  # get_functions is in inp_dump.py, this function read the bmp.bz2 file to generate addr->function dict
  functions = inp.get_functions(input_file)

  levels = func.classify_functions(functions)
  # print(list(functions.itervalues()),levels)
  func.analyze_functions(functions, levels)
  
  # see what happens when randomizing again and again and again...\
  disp_iter = 0
  for i_r in range(n_randomize):
    curr_time = time.time()
    if curr_time - start_time > 20*60:
      break
  
    global_diffs = []
    changed_bytes = set()
    changed_insts = set()

    # transform counts
    transform_counts = [0]*len(ALLOWED_TRANSFORMS)
    
    i=0
    for f in filter(lambda x: x.level != -1, functions.itervalues()):
      section = pe_file.get_section_by_rva(f.addr - imagebase)
      if 'reloc' not in section.Name:
        orig_f = copy.deepcopy(f)
      else:
        continue

      # skip the SEH prolog and epilog functions .. they cause trouble
      if "_SEH_" in f.name:  
        continue

      selected_transform = random.choice(ALLOWED_TRANSFORMS)
      transform_counts[ALLOWED_TRANSFORMS.index(selected_transform)] += 1
      
      if selected_transform=='equiv': # equivs
        diffs, c_b, c_i = equiv.do_equiv_instrs(f, p=0.5)
        if diffs:
          changed_bytes.update(c_b)
          changed_insts.update(c_i)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      elif selected_transform=='swap': # swaps
        swap.liveness_analysis(f.code)
        live_regs = swap.get_reg_live_subsets(f.instrs, f.code, f.igraph)
        swaps = swap.get_reg_swaps(live_regs)
        diffs, c_b, c_i = swap.do_multiple_swaps(f, swaps, p=0.5)
        if diffs:
          changed_bytes.update(c_b)
          changed_insts.update(c_i)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      elif selected_transform=='preserv': # preservs
        preservs, avail_regs = preserv.get_reg_preservations(f)
        diffs, c_b, c_i = preserv.do_reg_preservs(f, preservs, avail_regs, p=0.5)
        if diffs:
          changed_bytes.update(c_b)
          changed_insts.update(c_i)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      elif selected_transform=='reorder': # reorders
        diffs, c_b = reorder.do_random_reordering(f, pe_file)
        
        if diffs:
          changed_bytes.update(c_b)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      elif selected_transform=='disp': # displacements
        diffs, c_b, c_i = disp.displace_block(f, disp_state)
        
        if diffs:
          changed_bytes.update(c_b)
          changed_insts.update(c_i)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      elif selected_transform=='semnops': # semantic nops
        diffs, c_b = semnops.do_semnops(f)
        if diffs:
          changed_bytes.update(c_b)
          global_diffs.extend(diffs)
          patch(pe_file, disp_state, diffs)
      else:
        raise ValueError('Unknown transform type: %s'%selected_transform)
      
      
      if diffs:
        filename = os.path.basename(input_file)
        output_file = os.path.join(saved_root, filename.replace(".exe", "") + "_patched")
        if selected_transform=='disp':
          disp_iter += 1
          adj_pe = peLib.AdjustPE(pe_file)
          adj_pe.update_displacement(disp_state, data_hash, size_increasement_budget, disp_iter=disp_iter)
          
          peLib.write_pe(output_file, pe_file, epilog)

          if disp_state.peinfo.getRelocationSize()>0 and hasattr(disp_state.pe, 'DIRECTORY_ENTRY_BASERELOC'):
            disp._merge_file(output_file, data_hash)

        else:
          peLib.write_pe(output_file, pe_file, epilog)

          
        curr_bytez = open(output_file,'rb').read()
        curr_embed_x, curr_embed_x_grad, curr_score = clsf.get_score(curr_bytez)
      
        if curr_score<clsf.clsf_threshold:
          return calc_sha256(curr_bytez), curr_bytez, True

        if judge_grad(min_embed_x, curr_embed_x, min_embed_x_grad):
          min_score = curr_score
          min_score_bytez = curr_bytez
          min_embed_x = curr_embed_x
          min_embed_x_grad = curr_embed_x_grad
        else:
          functions[f.addr] = orig_f

        pe_file, epilog = peLib.read_pe(pe_data = min_score_bytez, remove_rubbish=False)

    # reanalyze functions (if not the last iteration)
    if i_r<n_randomize-1:
      reanalyze_functions(functions, levels)

  return None, None, False
  
def init(l, s, t, log):
  global lock
  global success
  global total
  global logger
  lock = l
  success = s
  total = t
  logger = log

def attack_multiprocesses(threadsnum, binary_paths, clsf, n_randomize, size_increasement, success_value, total_value):
  success = Value('i', success_value)
  total = Value('i', total_value)
  lock = Lock()
  partial_attack = partial(attack_for_one_data, clsf=clsf, n_randomize=n_randomize, size_increasement=size_increasement)
  pool = multiprocessing.Pool(threadsnum, initializer=init, initargs=(lock,success,total,logger,))
  pool.map(partial_attack, binary_paths)
  pool.close()
  pool.join()


class MakeOverAttacker(Problem_Space):
  def __init__(self, **kwargs):
    super(MakeOverAttacker, self).__init__(**kwargs)
    self.reset()

    random.seed(23)
    self.n_randomize=200
    self.size_increasement=0.05

  def __call__(self, clsf, input_):
    self._attack_begin()
    sha256, bytez, label = attack_for_one_data(input_, clsf, self.n_randomize, self.size_increasement)
    self._attack_finish()
    if label:
      self._succeed()
    return sha256, label



if __name__=="__main__":
  random.seed(23)
  base_url = 'http://127.0.0.1:8080/predictions/malconv_grad'
  log_root = "/home/zhoubolin_tmp/MakeOver/1013/enhanced-binary-diversification/logs_tmp"
  threshold_type = '100fpr'
  n_randomize=200
  size_increasement=0.05
  clsf = MalconvClient(base_url=base_url, threshold_type=threshold_type, grad_output=True)

  logger_name = '{}_{}_iter{}_inc{}.log'.format(clsf.name, clsf.threshold_type, n_randomize, str(size_increasement).replace('.',''))
  logger = create_logger(logger_name, log_root)

  log_dict = parse_log(os.path.join(log_root, logger_name))
  _binary_paths = glob.glob('/home/zhoubolin_tmp/MakeOver/1013/enhanced-binary-diversification/mal_samples/*')
  binary_paths = list(filter(lambda x: x.count('.')==0 and x.count('_patched')==0 and os.path.basename(x) not in log_dict.keys(), _binary_paths))

  success_value = 0
  total_value = 0
  # for item in log_dict:
  #   if 'total' in log_dict[item].keys():
  #     total = log_dict[item]['total']
  #     success = log_dict[item]['bypassed_num']
  #     if total>total_value:
  #       total_value = total
  #     if success>success_value:
  #       success_value = success
  
  # binary_paths = ['/home/wzy/enhanced-binary-diversification/mal_samples/52e817efefd0ba90907fe7619283991b19b8fae48ed566aaa6b522e6ecf47363']
  attack_multiprocesses(binary_paths, clsf, n_randomize, size_increasement, logger, success_value, total_value)

  # nohup python -u /home/wzy/enhanced-binary-diversification/binary_transform_test.py >> log.file 2>&1 &
